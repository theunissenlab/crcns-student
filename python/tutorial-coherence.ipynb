{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coherence Tutorial.  \n",
    "\n",
    "**The goal of this tutorial is to practice estimating the Noise and Signal from a neural response.**\n",
    "\n",
    "The signal is the mean response.  This mean response is also what is predicted in the context of GLMs.  GLMs predict the mean of a Noise distribution (generally Normal, Poisson or Binomial).  \n",
    "\n",
    "By estimating the mean and the noise directly from the data one can obtain the ceiling value of that can be predicted.  \n",
    "The coherence is a measure of signal to noise ratio as a function of frequency.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "Make sure that you download the data and install all of the necessary requirements before running this code! See the following link for more details:\n",
    "\n",
    "[Getting Started](../getting_started.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from glob import glob\n",
    "import mne\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from numpy.fft import fftshift, ifft, fft, fftfreq\n",
    "\n",
    "import mnespikes\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next three sections allow you to load and visualize single unit data from\n",
    "The theunissen lab. Your goals are:\n",
    "\n",
    "1. Get familiar with this data structure\n",
    "2. Load your own data in a similar structure.\n",
    "\n",
    "For the Theunissen data you can specify a directory for three brain regions and three example neurons in each.: 'mld' is the avian auditory midbrain 'ov' is the avian auditory thalamus 'l2a' is the avian auditory cortex each region has a 'good', 'avg', and 'bad' dataset, corresponding to the signal to noise ratio, quantified by information values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next few cells we are reading all of the data and storing it in a pandas data frame.\n",
    "The data consists of stimulus-response pairs.  Here there are 10 trials per stimulus and therefore the same stimulus is used multiple times.  We are also going to select the stimulus/response files corresponding to conspecific song. \n",
    "\n",
    "To use this code on your own data, you will need to write your own data load function for your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change this if you move around files\n",
    "path_base = os.path.join('../')\n",
    "\n",
    "# For example you can specify an entire path\n",
    "# path_base = '/Users/frederictheunissen/Documents/Classes/Summer Course/2016/theunissen_tutorials'\n",
    "\n",
    "data_files = glob(os.path.join(path_base, 'data', '*', '*', '*'))\n",
    "# spikes = glob('../data/*/*/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data and store it into a pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['location', 'quality', 'kind', 'number']\n",
    "stims = {name: [] for name in columns}\n",
    "stims['path'] = []\n",
    "spikes = {name: [] for name in columns}\n",
    "spikes['spike_times'] = []\n",
    "\n",
    "# Loop through our datafiles and begin collecting information from each\n",
    "for dfile in data_files:\n",
    "    if 'stim' in dfile:\n",
    "        prefix = 'stim'\n",
    "    elif 'spike' in dfile:\n",
    "        prefix = 'spike'\n",
    "    else:\n",
    "        # Skip because it's not a stim or spike file\n",
    "        continue\n",
    "    with open(dfile, 'r') as ff:\n",
    "        # Pull metadata\n",
    "        location_quality, kind, number = dfile.split(os.sep)[-3:]\n",
    "        location, quality = location_quality.split('_')\n",
    "        stimnumber = int(number.replace(prefix, ''))\n",
    "        \n",
    "        # If it's a stimulus file, grab the fields we want and store it with the other stim files\n",
    "        if prefix == 'stim':\n",
    "            dpath = ff.read().strip()\n",
    "            this_columns = columns + ['path']\n",
    "            iter_data = [location, quality, kind, stimnumber, dpath]\n",
    "            for column, data in zip(this_columns, iter_data):\n",
    "                stims[column].append(data)\n",
    "        # If it's a spike file, read the spiketimes and append them to a spiketimes list\n",
    "        elif prefix == 'spike':\n",
    "            with open(dfile, 'r') as ff:\n",
    "                spike_times = ff.readlines()\n",
    "                spike_times = [ii.strip() for ii in spike_times]\n",
    "                spike_times_float = []\n",
    "                for trial in spike_times:\n",
    "                    if len(trial) > 0:\n",
    "                        this_times = np.array(trial.split(' '), dtype=float)\n",
    "                    else:\n",
    "                        this_times = np.array([])\n",
    "                    spike_times_float.append(this_times)\n",
    "            this_columns = columns + ['spike_times']\n",
    "            iter_data = [location, quality, kind, stimnumber, spike_times_float]\n",
    "            for column, data in zip(this_columns, iter_data):\n",
    "                spikes[column].append(data)\n",
    "\n",
    "# Wrap everything in a dataframe for some extra functionality\n",
    "stims = pd.DataFrame(stims)\n",
    "spikes = pd.DataFrame(spikes)\n",
    "data = pd.merge(stims, spikes)\n",
    "\n",
    "# Expand the data so that each row is a single instance\n",
    "tmp_data = []\n",
    "for ii, row in data.iterrows():\n",
    "    for jj, trial in enumerate(row['spike_times']):\n",
    "        this_data = row.copy()\n",
    "        this_data['spike_times'] = trial\n",
    "        this_data['repetition'] = jj\n",
    "        tmp_data.append(this_data)\n",
    "data = pd.DataFrame(tmp_data)\n",
    "data = data.drop('number', axis=1)\n",
    "\n",
    "# Finally convert all spike times to seconds (they are currently in milliseconds)\n",
    "data['spike_times'] = data['spike_times'].apply(lambda a: [ii / 1e3 for ii in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Displaying the panda data frame.\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess audio\n",
    "\n",
    "Here we are going to calculate a spectrogram for each unique sound file.  We are going to do this using the time-frequency routines from mne: Check out https://www.martinos.org/mne/stable/generated/mne.time_frequency.tfr_array_morlet.html#mne.time_frequency.tfr_array_morlet\n",
    "\n",
    "Note - for spiking data there are 10 repetitions of audio for each file. This corresponds to a single audio file, which we'll load in here in order to calculate the spectrogram of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_audio_files = data['path'].unique()\n",
    "\n",
    "# Define the frequencies that will be extracted\n",
    "# freqs = np.logspace(np.log10(500), np.log10(10000), 50)  \n",
    "freqs = np.linspace(500, 10000, 50)\n",
    "\n",
    "decimate = 32  # How much do we wish to decimate the resulting spectrogram\n",
    "n_cycles = freqs // 100  # Now many cycles for each wavelet\n",
    "spectrograms = {}\n",
    "for audio_file in tqdm(all_audio_files):\n",
    "    sfreq_audio, audio = wavfile.read(os.path.join(path_base, 'data', 'all_stims', audio_file))\n",
    "    time_audio = np.arange(audio.shape[0]) / float(sfreq_audio)\n",
    "    \n",
    "    # Perform the TFR on this sound and store the result\n",
    "    tfr = mne.time_frequency.tfr_array_morlet(audio[np.newaxis, np.newaxis, :],\n",
    "                                              sfreq_audio, freqs, decim=decimate,\n",
    "                                              n_cycles=n_cycles)\n",
    "    sfreq_audio /= decimate\n",
    "    spectrograms[audio_file] = tfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot a spectrogram of a single stimulus as an example.  Here we choose the 4th stim.\n",
    "\n",
    "plt_audio = spectrograms[all_audio_files[0]].squeeze()\n",
    "time_audio = np.arange(plt_audio.shape[1]) / float(sfreq_audio)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.pcolormesh(time_audio, freqs, np.log(np.abs(plt_audio)))\n",
    "ax.set(xlabel='Time (s)', ylabel='Frequency (Hz)', ylim=[500, 8000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NOTE: we could also use either matplotlib:\n",
    "sfreq_audio, audio = wavfile.read(os.path.join(path_base, 'data', 'all_stims', all_audio_files[0]))\n",
    "fig, ax = plt.subplots()\n",
    "_ = ax.specgram(audio, Fs=sfreq_audio, NFFT=2**8)\n",
    "ax.set(ylim=[500, 8000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Or use the theunissen lab soundsig.sound package.\n",
    "    # Install soundsig from the theunissen github repo: https://github.com/theunissenlab/soundsig.git\n",
    "    from soundsig.sound import BioSound\n",
    "\n",
    "    # Read the audio from wave\n",
    "    sfreq_audio, audio = wavfile.read(os.path.join(path_base, 'data', 'all_stims', all_audio_files[0]))\n",
    "\n",
    "    # Make a BioSound object\n",
    "    myBioSound = BioSound(soundWave=audio, fs=sfreq_audio, emitter='Conspecific', calltype = 'Song')\n",
    "\n",
    "    # Extract some acoustical features\n",
    "    # Calculate amplitude enveloppe\n",
    "    myBioSound.ampenv()\n",
    "\n",
    "    # Calculate the power spectrum\n",
    "    myBioSound.spectrum(f_high=10000)\n",
    "\n",
    "    # Calcualte the spectrogram\n",
    "    myBioSound.spectroCalc(spec_sample_rate=500)\n",
    "\n",
    "    # Plot it\n",
    "    myBioSound.plot()\n",
    "except:\n",
    "   print(\"This code didn't work probably because you're on Python 3 instead of 2!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Or we could also use librosa\n",
    "# This is the most powerful for audio analysis, though it's kind of a pain to install\n",
    "import librosa as lr\n",
    "import librosa.display as lrd\n",
    "\n",
    "# Define a gaussian window\n",
    "gauss_std = 80\n",
    "window = ('gaussian', gauss_std)\n",
    "\n",
    "# Calculate / plot the STFT\n",
    "stft = lr.stft(audio, window=window, n_fft=2**8)\n",
    "ax = lrd.specshow(lr.amplitude_to_db(stft), sr=sfreq_audio, y_axis='linear')\n",
    "ax.set(ylim=[500, 8000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess spikes\n",
    "Neuronal spiking data is essentially a collection of times, with each timepoint corresponding to one spike. Each spike file contains multiple repetitions of the same stimulus. These spikes are all from the same neuron.\n",
    "\n",
    "To do this we'll use a small helper package called `mne-spikes`. This lets you wrangle some spiking data and quickly output it as a timeseries. It also has the ability to output data in an MNE-python class, which makes it easy to visualize and analyze.\n",
    "\n",
    "See the following links for more information about the `Neuron` class:\n",
    "\n",
    "* http://predictablynoisy.com/mne-spikes/\n",
    "* http://predictablynoisy.com/mne-spikes/_as_gen/mnespikes.Neuron.html#mnespikes.Neuron\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We are going to look at the data from one neuron from l2a that has poor signal to noise ratio.\n",
    "this_location = 'l2a'\n",
    "this_data = data.query('quality == \"bad\" and location == @this_location')\n",
    "spikes = this_data['spike_times'].values\n",
    "\n",
    "# We can use this to determine how to group our events.\n",
    "# \"kind\" corresponds to the type of sound (e.g., conspecific)\n",
    "# \"path\" corresponds to the file path of the sound\n",
    "grouping_kind = 'path'\n",
    "event_types = this_data[grouping_kind].values\n",
    "\n",
    "# Store the spiking data in the Neuron class.\n",
    "neuron = mnespikes.Neuron(spikes, sfreq=50.0, events=event_types,\n",
    "                          tmin=-1, tmax=5, name='neuron_{}'.format(this_location))\n",
    "\n",
    "neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = neuron.to_mne()\n",
    "# The 500 events correspond to 10 trials to 20 different song (conspecific), 10 trials to 10 different ml noise\n",
    "# and 10 trials to 20 ml noise with bird spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# As this is an MNE object, we can use MNE functions to do visualization.\n",
    "# The `average` method averages across all trials.\n",
    "av = epochs.average([0])\n",
    "av.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll select all of the trials that correspond to a single filename. Remember we'll have 10 repetitions per filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print a list of the file names in this MNE object\n",
    "print(epochs.event_id.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select trials of a particular condition type and clip to a maximum of 3 seconds\n",
    "filename = '008B5A5C0C3E76BFBF97278658FB6309.wav'\n",
    "tmin = -.5\n",
    "tmax = 3\n",
    "epochs_con = epochs[filename].crop(tmin, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a raster plot of the epochs along with the average response below.\n",
    "### NOTE: If it seems like there are no spikes being plotted, try decreasing the sampling\n",
    "### frequency of the Neuron when constructing it above. If there are too mnay timepoints, then the\n",
    "### spike visualizations can get hidden by all of the whitespace.\n",
    "picks = [0]  # This tells MNE which channel to plot...in this case, we have only one channel\n",
    "fig = epochs_con.plot_image(picks, show=False, vmin=0, cmap='Greys')\n",
    "fig[0].set_size_inches(15, 5)\n",
    "fig[0].axes[0].set(ylabel='spikes / s', ylim=[0, None],\n",
    "                   title='Neuron: {} | Filename: {}'.format(neuron.name, filename));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Firing rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs._data = mne.filter.filter_data(epochs._data, epochs.info['sfreq'], None, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_bootstraps = 100\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "cmap = plt.cm.tab10\n",
    "plot_dtypes = list(epochs.event_id.keys())[:10]\n",
    "for ii, dtype in enumerate(plot_dtypes):\n",
    "    this_epochs = epochs[dtype].crop(0, 3)\n",
    "    this_data = this_epochs._data.squeeze()\n",
    "    this_color = cmap(float(ii) / len(plot_dtypes))\n",
    "    boot_means = np.zeros([n_bootstraps, this_data.shape[-1]])\n",
    "    ixs = np.random.randint(0, len(this_data), len(this_data) * n_bootstraps).reshape([n_bootstraps, -1])\n",
    "    for boot, this_ix in enumerate(ixs):\n",
    "        this_boot = this_data[this_ix].mean(0)\n",
    "        boot_means[boot] = this_boot\n",
    "        \n",
    "    clo, chi = np.percentile(boot_means, [2.5, 97.5], axis=0)\n",
    "    ax.fill_between(this_epochs.times, clo, chi, color=this_color, label=dtype, alpha=.9)\n",
    "ax.legend(loc=(1.05, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Calculate the noise for each trial and display it\n",
    "\n",
    "Calculate the noise using a signal generated from all trials as well as a signal that does not incldue the trial for wich you calculate the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choose a very good neuron from the auditory midbrain.\n",
    "quality = 'good'\n",
    "location = 'mld'\n",
    "name = '{}_{}'.format(quality, location)\n",
    "this_data = data.query('quality == @quality and location == @location and kind==\"conspecific\"')\n",
    "\n",
    "# Arguments used for filtering.\n",
    "filt_kwargs = dict(l_freq=None, h_freq=20, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### We have started this loop that uses mnespikes.Neuron - see if you can fill it in to calculate the noise and\n",
    "### the delete one noise\n",
    "\n",
    "# Setting up a grid of plost\n",
    "n_cols = 5\n",
    "n_rows = int(np.ceil(len(this_data.groupby('path')) / n_cols))\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 5*n_rows))\n",
    "\n",
    "# List for the noise, the delete one noise (noise_subset) and the signal\n",
    "noise_tot = []\n",
    "noise_subset_tot = []\n",
    "signal_tot = []\n",
    "\n",
    "# Looping through all the data files that match the query.\n",
    "for iifile, ((wavfile, i_data), ax) in enumerate(zip(this_data.groupby('path'), axs.ravel())):\n",
    "    \n",
    "    # Getting the data and storing it as a Neuron object\n",
    "    spikes = i_data['spike_times'].values\n",
    "    event_types = i_data['kind'].values\n",
    "    neuron = mnespikes.Neuron(spikes, sfreq=1000.0, events=event_types,\n",
    "                    tmin=-.5, tmax=5., name='neuron_{}'.format(name))\n",
    "    \n",
    "    # This is how you can calculate the mean (or psth)\n",
    "    signal = neuron.spikes.mean(0)\n",
    "    \n",
    "    # Loooping through trials - as in the trial to be deleted\n",
    "    for ii, trial in enumerate(neuron.spikes):\n",
    "        ixs = list(range(i_data.shape[0]))\n",
    "        ixs.pop(ii)   # Deletes the current trial from the list of trials\n",
    "        \n",
    "        # Make variables called: \n",
    "        #    signal_subset: the average signal with the current trial deleted\n",
    "        #    noise_all: the noise for the current trial using the signal obtained from all trials\n",
    "        #    noise_subset: the noise for the current trial using the signal obtained from all the other trials (deleting this one)\n",
    "        #  Append: noise_all to noise_tot and noise_subset to noise_subset_tot.  We are going to use those later on to calculate\n",
    "        # signal to noise ratios and coherence.\n",
    "### BEGIN SOLUTION        \n",
    "        signal_subset = neuron.spikes[ixs].mean(0)\n",
    "        noise_all = trial - signal\n",
    "        noise_subset = trial - signal_subset\n",
    "        \n",
    "        noise_subset_tot.append(noise_subset)\n",
    "        noise_tot.append(noise_all)\n",
    "        signal_tot.append(signal)\n",
    "### END SOLUTION\n",
    "\n",
    "        if ii == 0:\n",
    "            ax.plot(neuron.time, mne.filter.filter_data(trial, neuron.sfreq, **filt_kwargs),\n",
    "                    color='k', label='single trial')\n",
    "            ax.plot(neuron.time, mne.filter.filter_data(signal, neuron.sfreq, **filt_kwargs),\n",
    "                    color='k', ls='--', label='signal')\n",
    "            ax.plot(neuron.time, mne.filter.filter_data(noise_all, neuron.sfreq, **filt_kwargs),\n",
    "                    color='r', label='noise')\n",
    "            ax.plot(neuron.time, mne.filter.filter_data(noise_subset, neuron.sfreq, **filt_kwargs),\n",
    "                    color='r', ls='--', label='noise (subset)')\n",
    "            ax.set(title='File {}'.format(iifile), xlim=[None, 2])\n",
    "axs[0, -1].legend()\n",
    "\n",
    "# Collect the saved signal / noise from each trial\n",
    "noise_subset_tot = np.array(noise_subset_tot)\n",
    "noise_tot = np.array(noise_tot)\n",
    "signal_tot = np.array(signal_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Calculate the noise and signal psd obtained by averaging and by averaging after deleting one. Is the noise white? Also plot the Signal to Noise ratio obtained in with the two estimates of noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Hint: to calculate the power spectra you can use mne's time-frequency power spectrum estimation routines.\n",
    "## Eg. https://www.martinos.org/mne/stable/generated/mne.time_frequency.psd_array_welch.html#mne.time_frequency.psd_array_welch\n",
    "## You are going to use signal_tot, noise_tot and noise_subset_tot calculated above.\n",
    "\n",
    "# Calculate the three psd here (signal, noise, delete one noise)\n",
    "### BEGIN SOLUTION\n",
    "psignal, freqs = mne.time_frequency.psd_array_welch(signal_tot, neuron.sfreq, n_overlap=125)\n",
    "pnoise, freqs = mne.time_frequency.psd_array_welch(noise_tot, neuron.sfreq, n_overlap=125)\n",
    "pnoise_subset, freqs = mne.time_frequency.psd_array_welch(noise_subset_tot, neuron.sfreq, n_overlap=125)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the psds here\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(freqs, 10 * np.log10(psignal.mean(0)), c='k', label='Signal')\n",
    "ax.plot(freqs, 10 * np.log10(pnoise.mean(0)), c='r', label='Noise')\n",
    "ax.plot(freqs, 10 * np.log10(pnoise_subset.mean(0)), c='r', ls='--', label='JN Noise')\n",
    "\n",
    "ax.set(xlim=[0, neuron.sfreq / 2], xlabel='Frequency (Hz)', ylabel='Power (dB)')\n",
    "plt.legend()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the SNR in dB units here\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(freqs, 10.0*np.log10(psignal.mean(0) / pnoise.mean(0)), 'k', label='All')\n",
    "ax.plot(freqs, 10.0*np.log10(psignal.mean(0) / pnoise_subset.mean(0)), 'k--', label='Delete One')\n",
    "ax.set(ylabel='SNR (dB)', xlabel='Frequency (Hz)')\n",
    "plt.legend()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Is the noise gaussian?\n",
    "\n",
    "### Hints: You can use the scipy.stats norm functions and matplotlib hist function. You might also want to low pass filter the noise and try different values of cutoff frequency (eg. 10 Hz, 100 Hz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "noise_subset_filt = mne.filter.filter_data(noise_subset, neuron.sfreq, None, 100)\n",
    "noise_mu, noise_std = norm.fit(noise_subset_filt.ravel())\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(noise_subset_filt, bins=50, normed=True)\n",
    "\n",
    "plt_x = np.linspace(-.05, .05, 100)\n",
    "ax.plot(plt_x, norm.pdf(plt_x, noise_mu, noise_std))\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Calculate and display the coherence calculated from the signal to noise ratio. Calculate the information form this coherence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The coherence is S/(S+N)\n",
    "\n",
    "# Add your calculation here\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "coh_snr = psignal.mean(0) / (pnoise.mean(0) + psignal.mean(0))\n",
    "\n",
    "# The information is obtained by integrating (summing) the log2(1 - coherence).\n",
    "dfreq = freqs[1] - freqs[0]      # The delta frequency\n",
    "info_snr = np.sum(-np.log2(1 - coh_snr)) * dfreq\n",
    "\n",
    "coh_snr_d1 = psignal.mean(0) / (pnoise_subset.mean(0) + psignal.mean(0))\n",
    "info_snr_d1 = np.sum(-np.log2(1 - coh_snr_d1)) * dfreq\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add your plot here\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(freqs, coh_snr, 'k', label='all trials')\n",
    "ax.plot(freqs, coh_snr_d1, 'k--', label='left out trial')\n",
    "ax.set(ylabel='Coherence', xlabel='Frequency (Hz)',\n",
    "       title='Total Information: UB {:.1f} LB {:.1f} bits/s'.format(\n",
    "           info_snr, info_snr_d1))\n",
    "ax.legend()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance Estimation using the Coherence.\n",
    "\n",
    "We are now going to calculate the coherence and channel capacity (the upper bound) using Hsu, Borst, Theunissen methodology (Hsu, A., A. Borst and F. E. Theunissen (2004). \"Quantifying variability in neural responses and its application for the validation of model predictions.\" Network 15(2): 91-109.)\n",
    "\n",
    "In order to do that we need to take the raw spike times, split them into even and odd trials, and compute PSTHs for each half. We will also generate a fake prediction by adding noise to the psth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divinding the data into Odd and Even Trials and obtaing the average response for each half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "psthAll = []\n",
    "psthEven = []\n",
    "psthOdd = []\n",
    "\n",
    "# Looping through selected data (this _data) in the pandas data frame.\n",
    "for iifile, (wavfile, i_data) in enumerate(this_data.groupby('path')):\n",
    "    \n",
    "    # Making a Neuron Data Structure.\n",
    "    spikes = i_data['spike_times'].values\n",
    "    event_types = i_data['kind'].values\n",
    "    neuron = mnespikes.Neuron(spikes, sfreq=1000.0, events=event_types,\n",
    "                    tmax=5, name='neuron_{}'.format(ii))\n",
    "    psth = neuron.spikes.mean(0)\n",
    "    psth_odd = np.zeros(psth.shape)\n",
    "    psth_even = np.zeros(psth.shape)\n",
    "    n_odd = 0\n",
    "    n_even = 0\n",
    "    for ii, trial in enumerate(neuron.spikes):\n",
    "        if ii % 2 != 0 :\n",
    "            psth_odd += neuron.spikes[ii,:]\n",
    "            n_odd += 1\n",
    "        else:\n",
    "            psth_even += neuron.spikes[ii,:]\n",
    "            n_even += 1\n",
    "    psth_odd /= n_odd\n",
    "    psth_even /= n_even\n",
    "    \n",
    "    psthAll.append(psth)\n",
    "    psthEven.append(psth_even)\n",
    "    psthOdd.append(psth_odd)\n",
    "\n",
    "psthAll = np.asarray(psthAll).ravel()\n",
    "psthEven = np.asarray(psthEven).ravel()\n",
    "psthOdd = np.asarray(psthOdd).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A model prediction is obtained by adding gaussian noise to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noiseGain = 0.05 # play with gain to increase or decrease PSTH corruption\n",
    "noise = np.random.randn(psthAll.shape[0]) * noiseGain # make some noise!\n",
    "prediction = psthAll + noise # corrupt PSTH\n",
    "\n",
    "prediction[prediction < 0] = 0 # Rectify\n",
    "prediction[prediction > 1] = 1 # Saturate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot these 1/2 psths and the prediction.\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(psthEven, 'r', label = 'Data 1')\n",
    "ax.plot(psthOdd, 'b', label = 'Data 2')\n",
    "ax.plot(prediction, 'k', label = 'Model')\n",
    "ax.set(xlabel='Time (ms)', ylabel='Firing rate (kHz)', xlim=[0, 200])\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a vanilla coherence function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coherence(x, y, fsamp, nwindow):\n",
    "    \"\"\"A vanilla function to calculate the coherence between two 1d time series.\n",
    "    \"\"\"\n",
    "    npts = len(x)    \n",
    "    nchunk = int(npts/nwindow)\n",
    "        \n",
    "    # List to save values\n",
    "    powx = []\n",
    "    powy = []\n",
    "    crossxy = []\n",
    "    \n",
    "    iend = 0\n",
    "    for i in range(nchunk):\n",
    "        istart = iend\n",
    "        iend = istart + nwindow\n",
    "        \n",
    "        xchunk = x[istart:iend]\n",
    "        ychunk = y[istart:iend]\n",
    "        \n",
    "        xf = fft(xchunk)\n",
    "        yf = fft(ychunk)\n",
    "        \n",
    "        powx.append(np.real(xf*xf.conj())) \n",
    "        powy.append(np.real(yf*yf.conj()))\n",
    "        \n",
    "        crossxy.append(xf*yf.conj())\n",
    "    \n",
    "    freq = fftfreq(nwindow, 1.0/fsamp)\n",
    "    \n",
    "    pxx = np.asarray(powx).sum(0)\n",
    "    pyy = np.asarray(powy).sum(0)\n",
    "    cxy = np.asarray(crossxy).sum(0)\n",
    "    \n",
    "    \n",
    "    coh = np.abs(cxy)**2/(pxx*pyy)\n",
    "    \n",
    "    return coh[:nwindow//2], freq[:nwindow//2]  # Double // means keep the dtype the same\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of the estimation of the coherences between one spike and the mean (cohBound) amd betweem one spike and the prediction (cohModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute coherence between the two half psths:\n",
    "fsamp = 1000.0\n",
    "nwindow = 512\n",
    "numTrials = 10 # Code should look for this number\n",
    "\n",
    "# Coherence between two 1/2 of the psth and upper bound\n",
    "coh_12, c_freqs = coherence(psthEven, psthOdd, fsamp, nwindow)\n",
    "kdown = (-numTrials + numTrials * np.sqrt(1 / coh_12)) / 2       # Eq. 8 of Hsu et al.\n",
    "cohBound = 1 / (kdown + 1)\n",
    "\n",
    "# Coherence between the predicted and psth and prediction\n",
    "coh_pred, c_freqs = coherence(prediction, psthAll, fsamp, nwindow)\n",
    "rhs = (1 + np.sqrt(1.0 / coh_12)) / (-numTrials + numTrials*np.sqrt(1.0 / coh_12)+2) # rhs of Eq 11 in Hsu et. al\n",
    "cohModel = coh_pred * rhs;\n",
    "\n",
    "# Obtain Information values\n",
    "dfreq = c_freqs[1] - c_freqs[0]      # The delta frequency\n",
    "infoBound = np.sum(-np.log2(1 - cohBound)) * dfreq\n",
    "infoModel = np.sum(-np.log2(1 - cohModel)) * dfreq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(c_freqs, cohBound, label='Bound')\n",
    "ax.plot(c_freqs, cohModel, label='Model')\n",
    "ax.set(ylabel='Coherence', xlabel='Frequency (Hz)', title='Information: Bound {:.1f} Model {:.1f} bits/s'.format(\n",
    "    infoBound, infoModel))\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Coherence')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
